{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tensorflow_Basics_part2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDovpbJ8xmEP"
      },
      "source": [
        "PRETRAINED MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3jk8tkgMNPRb",
        "outputId": "73bb9e28-0c71-4f76-eaaa-6f1790ee303c"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist, cifar10\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "# To Avoid GPU errors\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "# ================================================ #\n",
        "#                  Pretrained-Model                #\n",
        "# ================================================ #\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "x_train = x_train.astype(\"float32\") / 255.0\n",
        "x_test = x_test.astype(\"float32\") / 255.0\n",
        "\n",
        "def my_model():\n",
        "    inputs = keras.Input(shape=(32,32,3))\n",
        "    x = layers.Conv2D(32, 3, padding='same')(inputs)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(64, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.MaxPool2D()(x)\n",
        "    x = layers.Conv2D(128, 3, padding='same')(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = keras.activations.relu(x)\n",
        "    x = layers.Flatten()(x)   \n",
        "    outputs = layers.Dense(10)(x)\n",
        "    model = keras.Model(inputs = inputs, outputs = outputs) \n",
        "    return model\n",
        "\n",
        "\n",
        "# SavedModel format or HDF5 format\n",
        "model = my_model()\n",
        "# model = keras.models.load_model('saved_model/')\n",
        "# model.load_weights('checkpoint_folder/')\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)\n",
        "model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n",
        "# model.save_weights('checkpoint_folder/')\n",
        "model.save(\"saved_model/\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "1563/1563 - 6s - loss: 1.2462 - accuracy: 0.5789\n",
            "Epoch 2/2\n",
            "1563/1563 - 5s - loss: 0.8130 - accuracy: 0.7179\n",
            "313/313 - 1s - loss: 0.9142 - accuracy: 0.6887\n",
            "INFO:tensorflow:Assets written to: saved_model/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thmCNZ14T4Yc"
      },
      "source": [
        "model = keras.models.load_model(\"/content/saved_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UORgpSMvT5G4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac9fff5-f462-4710-d6a9-57c2ec62eaff"
      },
      "source": [
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 10)                81930     \n",
            "=================================================================\n",
            "Total params: 176,074\n",
            "Trainable params: 175,626\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4U3uYtnSwoH-"
      },
      "source": [
        "model.trainable = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBFxSJDmT7-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0af933aa-d9b8-45b9-c0ae-0d59a0948bd2"
      },
      "source": [
        "base_inputs = model.layers[0].input\n",
        "base_outputs = model.layers[-2].output\n",
        "print(base_inputs)\n",
        "print(base_outputs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "KerasTensor(type_spec=TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float32, name='input_5'), name='input_5', description=\"created by layer 'input_5'\")\n",
            "KerasTensor(type_spec=TensorSpec(shape=(None, 8192), dtype=tf.float32, name=None), name='flatten_4/Reshape:0', description=\"created by layer 'flatten_4'\")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "StTiNf6fr__C"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTHcYO9crvlA"
      },
      "source": [
        "final_outputs = layers.Dense(10)(base_outputs)\n",
        "# final_outputs = layers.Dense(15)(base_outputs)\n",
        "new_model = keras.Model(inputs = base_inputs, outputs = final_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMWtyiauvQsL",
        "outputId": "b7944f37-27e2-4fdb-aaca-cf44d4d8341c"
      },
      "source": [
        "print(new_model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "conv2d_12 (Conv2D)           (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 32, 32, 32)        128       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_12 (TFOpLambda)   (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 16, 16, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 16, 16, 64)        18496     \n",
            "_________________________________________________________________\n",
            "batch_normalization_13 (Batc (None, 16, 16, 64)        256       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_13 (TFOpLambda)   (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 8, 8, 128)         73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_14 (Batc (None, 8, 8, 128)         512       \n",
            "_________________________________________________________________\n",
            "tf.nn.relu_14 (TFOpLambda)   (None, 8, 8, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 8192)              0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 10)                81930     \n",
            "=================================================================\n",
            "Total params: 176,074\n",
            "Trainable params: 81,930\n",
            "Non-trainable params: 94,144\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wr2oL-UvhQt",
        "outputId": "47e0f8d5-07a3-43a4-e612-453d0e1962ce"
      },
      "source": [
        "new_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "new_model.fit(x_train, y_train, batch_size=32, epochs=3, verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "1563/1563 - 4s - loss: 0.7753 - accuracy: 0.7300\n",
            "Epoch 2/3\n",
            "1563/1563 - 4s - loss: 0.5692 - accuracy: 0.8042\n",
            "Epoch 3/3\n",
            "1563/1563 - 4s - loss: 0.4857 - accuracy: 0.8340\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1fbd2c0470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkPORS2uxpn1"
      },
      "source": [
        "PRETRAINED KERAS MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWPfq7bjvTpI",
        "outputId": "6b6e9da2-a405-4d96-f929-368064081aed"
      },
      "source": [
        "x = tf.random.normal(shape=(5, 299, 299, 3))\n",
        "y = tf.constant([0,1,2,3,4])\n",
        "\n",
        "model = keras.applications.InceptionV3(include_top=True)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 3s 0us/step\n",
            "Model: \"inception_v3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_6 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 149, 149, 32) 864         input_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 149, 149, 32) 96          conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 149, 149, 32) 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 147, 147, 32) 9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 147, 147, 32) 96          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 147, 147, 32) 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 147, 147, 64) 18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 147, 147, 64) 192         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 147, 147, 64) 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling2D) (None, 73, 73, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 73, 73, 80)   5120        max_pooling2d_10[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 73, 73, 80)   240         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 73, 73, 80)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 71, 71, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 71, 71, 192)  576         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 71, 71, 192)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling2D) (None, 35, 35, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 35, 35, 64)   192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 35, 35, 64)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 35, 35, 48)   9216        max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 35, 35, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 35, 35, 48)   144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 35, 35, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 35, 35, 48)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 35, 35, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 35, 35, 192)  0           max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 35, 35, 64)   12288       max_pooling2d_11[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 35, 35, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 35, 35, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 35, 35, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 35, 35, 64)   192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 35, 35, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 35, 35, 96)   288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 35, 35, 32)   96          conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 35, 35, 64)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 35, 35, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 35, 35, 96)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 35, 35, 32)   0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 35, 35, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 35, 35, 64)   192         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 35, 35, 64)   0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 35, 35, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 35, 35, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 35, 35, 48)   144         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 35, 35, 96)   288         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 35, 35, 48)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 35, 35, 96)   0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 35, 35, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 35, 35, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 35, 35, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 35, 35, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 35, 35, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 35, 35, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 35, 35, 64)   192         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 35, 35, 96)   288         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 35, 35, 64)   192         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 35, 35, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 35, 35, 64)   0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 35, 35, 96)   0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 35, 35, 64)   0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 35, 35, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 35, 35, 64)   192         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 35, 35, 64)   0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 35, 35, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 35, 35, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 35, 35, 48)   144         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 35, 35, 96)   288         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 35, 35, 48)   0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 35, 35, 96)   0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 35, 35, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 35, 35, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 35, 35, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 35, 35, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 35, 35, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 35, 35, 64)   192         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 35, 35, 64)   192         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 35, 35, 96)   288         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 35, 35, 64)   192         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 35, 35, 64)   0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 35, 35, 64)   0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 35, 35, 96)   0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 35, 35, 64)   0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 35, 35, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 35, 35, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 35, 35, 64)   192         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 35, 35, 64)   0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 35, 35, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 35, 35, 96)   288         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 35, 35, 96)   0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 17, 17, 384)  995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 17, 17, 96)   82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 17, 17, 384)  1152        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 17, 17, 96)   288         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 17, 17, 384)  0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 17, 17, 96)   0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling2D) (None, 17, 17, 288)  0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 17, 17, 768)  0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_12[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 17, 17, 128)  384         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 17, 17, 128)  0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 17, 17, 128)  114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 17, 17, 128)  384         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 17, 17, 128)  0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 17, 17, 128)  98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 17, 17, 128)  114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 17, 17, 128)  384         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 17, 17, 128)  384         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 17, 17, 128)  0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 17, 17, 128)  0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 17, 17, 128)  114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 17, 17, 128)  114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 17, 17, 128)  384         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 17, 17, 128)  384         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 17, 17, 128)  0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 17, 17, 128)  0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 17, 17, 768)  0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 17, 17, 192)  147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 17, 17, 192)  172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 17, 17, 192)  172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 17, 17, 192)  576         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 17, 17, 192)  576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 17, 17, 192)  576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 17, 17, 192)  576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 17, 17, 192)  0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 17, 17, 192)  0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 17, 17, 192)  0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 17, 17, 192)  0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 17, 17, 768)  0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 17, 17, 160)  480         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 17, 17, 160)  0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 17, 17, 160)  179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 17, 17, 160)  480         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 17, 17, 160)  0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 17, 17, 160)  122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 17, 17, 160)  179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 17, 17, 160)  480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 17, 17, 160)  480         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 17, 17, 160)  0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 17, 17, 160)  0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 17, 17, 160)  179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 17, 17, 160)  179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 17, 17, 160)  480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 17, 17, 160)  480         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 17, 17, 160)  0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 17, 17, 160)  0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 17, 17, 768)  0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 17, 17, 192)  147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 17, 17, 192)  215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 17, 17, 192)  215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 17, 17, 192)  576         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 17, 17, 192)  576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 17, 17, 192)  576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 17, 17, 192)  576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 17, 17, 192)  0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 17, 17, 192)  0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 17, 17, 192)  0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 17, 17, 192)  0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 17, 17, 768)  0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 17, 17, 160)  480         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 17, 17, 160)  0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 17, 17, 160)  179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 17, 17, 160)  480         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 17, 17, 160)  0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 17, 17, 160)  122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 17, 17, 160)  179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 17, 17, 160)  480         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 17, 17, 160)  480         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 17, 17, 160)  0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 17, 17, 160)  0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 17, 17, 160)  179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 17, 17, 160)  179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 17, 17, 160)  480         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 17, 17, 160)  480         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 17, 17, 160)  0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 17, 17, 160)  0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 17, 17, 768)  0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 17, 17, 192)  147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 17, 17, 192)  215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 17, 17, 192)  215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 17, 17, 192)  576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 17, 17, 192)  576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 17, 17, 192)  576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 17, 17, 192)  576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 17, 17, 192)  0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 17, 17, 192)  0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 17, 17, 192)  0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 17, 17, 192)  0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 17, 17, 768)  0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 17, 17, 192)  576         conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 17, 17, 192)  0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 17, 17, 192)  258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 17, 17, 192)  576         conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 17, 17, 192)  0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 17, 17, 192)  258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 17, 17, 192)  576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 17, 17, 192)  576         conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 17, 17, 192)  0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 17, 17, 192)  0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 17, 17, 192)  258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 17, 17, 192)  258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 17, 17, 192)  576         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 17, 17, 192)  576         conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 17, 17, 192)  0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 17, 17, 192)  0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 17, 17, 768)  0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 17, 17, 192)  147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 17, 17, 192)  258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 17, 17, 192)  258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 17, 17, 192)  147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 17, 17, 192)  576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 17, 17, 192)  576         conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 17, 17, 192)  576         conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 17, 17, 192)  576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 17, 17, 192)  0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 17, 17, 192)  0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 17, 17, 192)  0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 17, 17, 192)  0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 17, 17, 768)  0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 17, 17, 192)  576         conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 17, 17, 192)  0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 17, 17, 192)  258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 17, 17, 192)  576         conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 17, 17, 192)  0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 17, 17, 192)  147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 17, 17, 192)  258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 17, 17, 192)  576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 17, 17, 192)  576         conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 17, 17, 192)  0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 17, 17, 192)  0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 8, 8, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 8, 8, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 8, 8, 320)    960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 8, 8, 192)    576         conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 8, 8, 320)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 8, 8, 192)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling2D) (None, 8, 8, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 8, 8, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_13[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_95 (Conv2D)              (None, 8, 8, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_95 (BatchNo (None, 8, 8, 448)    1344        conv2d_95[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 8, 8, 448)    0           batch_normalization_95[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 8, 8, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_96 (Conv2D)              (None, 8, 8, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 8, 8, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_96 (BatchNo (None, 8, 8, 384)    1152        conv2d_96[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 8, 8, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 8, 8, 384)    0           batch_normalization_96[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, 8, 8, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_97 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_98 (Conv2D)              (None, 8, 8, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 8, 8, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 8, 8, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 8, 8, 384)    1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, 8, 8, 384)    1152        conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_97 (BatchNo (None, 8, 8, 384)    1152        conv2d_97[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_98 (BatchNo (None, 8, 8, 384)    1152        conv2d_98[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_99 (Conv2D)              (None, 8, 8, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 8, 8, 320)    960         conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 8, 8, 384)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 8, 8, 384)    0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 8, 8, 384)    0           batch_normalization_97[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 8, 8, 384)    0           batch_normalization_98[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_99 (BatchNo (None, 8, 8, 192)    576         conv2d_99[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 8, 8, 320)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 8, 8, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 8, 8, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 8, 8, 192)    0           batch_normalization_99[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 8, 8, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_104 (Conv2D)             (None, 8, 8, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_104 (BatchN (None, 8, 8, 448)    1344        conv2d_104[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 8, 8, 448)    0           batch_normalization_104[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_101 (Conv2D)             (None, 8, 8, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_105 (Conv2D)             (None, 8, 8, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_101 (BatchN (None, 8, 8, 384)    1152        conv2d_101[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_105 (BatchN (None, 8, 8, 384)    1152        conv2d_105[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 8, 8, 384)    0           batch_normalization_101[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 8, 8, 384)    0           batch_normalization_105[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_102 (Conv2D)             (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_103 (Conv2D)             (None, 8, 8, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_106 (Conv2D)             (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_107 (Conv2D)             (None, 8, 8, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 8, 8, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_100 (Conv2D)             (None, 8, 8, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_102 (BatchN (None, 8, 8, 384)    1152        conv2d_102[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_103 (BatchN (None, 8, 8, 384)    1152        conv2d_103[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_106 (BatchN (None, 8, 8, 384)    1152        conv2d_106[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_107 (BatchN (None, 8, 8, 384)    1152        conv2d_107[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_108 (Conv2D)             (None, 8, 8, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_100 (BatchN (None, 8, 8, 320)    960         conv2d_100[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 8, 8, 384)    0           batch_normalization_102[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 8, 8, 384)    0           batch_normalization_103[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 8, 8, 384)    0           batch_normalization_106[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 8, 8, 384)    0           batch_normalization_107[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_108 (BatchN (None, 8, 8, 192)    576         conv2d_108[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 8, 8, 320)    0           batch_normalization_100[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 8, 8, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 8, 8, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 8, 8, 192)    0           batch_normalization_108[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 8, 8, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "avg_pool (GlobalAveragePooling2 (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 23,851,784\n",
            "Trainable params: 23,817,352\n",
            "Non-trainable params: 34,432\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pACofIBeyhV4",
        "outputId": "b3e15baf-ed44-472d-e1eb-40d374e521fb"
      },
      "source": [
        "base_inputs = model.layers[0].input\n",
        "base_outputs = model.layers[-2].output\n",
        "final_outputs = layers.Dense(5)(base_outputs)\n",
        "\n",
        "new_model = keras.Model(inputs = base_inputs, outputs = final_outputs)\n",
        "new_model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "new_model.fit(x, y, epochs=15, verbose=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "1/1 - 8s - loss: 1.6357 - accuracy: 0.4000\n",
            "Epoch 2/15\n",
            "1/1 - 0s - loss: 0.1968 - accuracy: 1.0000\n",
            "Epoch 3/15\n",
            "1/1 - 0s - loss: 6.7898e-04 - accuracy: 1.0000\n",
            "Epoch 4/15\n",
            "1/1 - 0s - loss: 1.9359e-04 - accuracy: 1.0000\n",
            "Epoch 5/15\n",
            "1/1 - 0s - loss: 1.0089e-04 - accuracy: 1.0000\n",
            "Epoch 6/15\n",
            "1/1 - 0s - loss: 6.6014e-05 - accuracy: 1.0000\n",
            "Epoch 7/15\n",
            "1/1 - 0s - loss: 5.3165e-05 - accuracy: 1.0000\n",
            "Epoch 8/15\n",
            "1/1 - 0s - loss: 4.7181e-05 - accuracy: 1.0000\n",
            "Epoch 9/15\n",
            "1/1 - 0s - loss: 4.5798e-05 - accuracy: 1.0000\n",
            "Epoch 10/15\n",
            "1/1 - 0s - loss: 4.6084e-05 - accuracy: 1.0000\n",
            "Epoch 11/15\n",
            "1/1 - 0s - loss: 4.6609e-05 - accuracy: 1.0000\n",
            "Epoch 12/15\n",
            "1/1 - 0s - loss: 4.7205e-05 - accuracy: 1.0000\n",
            "Epoch 13/15\n",
            "1/1 - 0s - loss: 4.7801e-05 - accuracy: 1.0000\n",
            "Epoch 14/15\n",
            "1/1 - 0s - loss: 4.7777e-05 - accuracy: 1.0000\n",
            "Epoch 15/15\n",
            "1/1 - 0s - loss: 4.7514e-05 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1ff8408b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktyuNQZRzedw"
      },
      "source": [
        "PRETRAINED TF HUB MODELS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UozBjkjzjcA"
      },
      "source": [
        "https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEiIHMTl0ViT",
        "outputId": "e933b46e-cfa3-46e5-bd78-7c8ff335c749"
      },
      "source": [
        "x = tf.random.normal(shape=(5, 299, 299, 3))\n",
        "y = tf.constant([0,1,2,3,4])\n",
        "\n",
        "url = 'https://tfhub.dev/google/imagenet/inception_v3/feature_vector/4'\n",
        "\n",
        "base_model = hub.KerasLayer(url, input_shape=(299,299,3))\n",
        "base_model.trainable=False\n",
        "model = keras.Sequential([\n",
        "    base_model,\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(5),                      \n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(x, y, batch_size=32, epochs=20, verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1/1 - 5s - loss: 1.6210 - accuracy: 0.2000\n",
            "Epoch 2/20\n",
            "1/1 - 0s - loss: 1.5491 - accuracy: 0.2000\n",
            "Epoch 3/20\n",
            "1/1 - 0s - loss: 1.3905 - accuracy: 0.6000\n",
            "Epoch 4/20\n",
            "1/1 - 0s - loss: 1.2997 - accuracy: 0.4000\n",
            "Epoch 5/20\n",
            "1/1 - 0s - loss: 1.1925 - accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "1/1 - 0s - loss: 1.0855 - accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "1/1 - 0s - loss: 0.9868 - accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "1/1 - 0s - loss: 0.8882 - accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "1/1 - 0s - loss: 0.7977 - accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "1/1 - 0s - loss: 0.7150 - accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "1/1 - 0s - loss: 0.6406 - accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "1/1 - 0s - loss: 0.5663 - accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "1/1 - 0s - loss: 0.4868 - accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "1/1 - 0s - loss: 0.4246 - accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "1/1 - 0s - loss: 0.3717 - accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "1/1 - 0s - loss: 0.3260 - accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "1/1 - 0s - loss: 0.2858 - accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "1/1 - 0s - loss: 0.2469 - accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "1/1 - 0s - loss: 0.2136 - accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "1/1 - 0s - loss: 0.1854 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1de7c3c7b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmZI5etv2EXy"
      },
      "source": [
        "TENSORFLOW DATASETS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoHXvZfY1nFm"
      },
      "source": [
        "import os \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uh6P_Ztw0mQw",
        "outputId": "8cf9836c-6344-4f2e-c20e-6f99324cfb2a"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=['train','test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=False,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "print(ds_info)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tfds.core.DatasetInfo(\n",
            "    name='mnist',\n",
            "    version=3.0.1,\n",
            "    description='The MNIST database of handwritten digits.',\n",
            "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
            "    features=FeaturesDict({\n",
            "        'image': Image(shape=(28, 28, 1), dtype=tf.uint8),\n",
            "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=10),\n",
            "    }),\n",
            "    total_num_examples=70000,\n",
            "    splits={\n",
            "        'test': 10000,\n",
            "        'train': 60000,\n",
            "    },\n",
            "    supervised_keys=('image', 'label'),\n",
            "    citation=\"\"\"@article{lecun2010mnist,\n",
            "      title={MNIST handwritten digit database},\n",
            "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
            "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
            "      volume={2},\n",
            "      year={2010}\n",
            "    }\"\"\",\n",
            "    redistribution_info=,\n",
            ")\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "id": "ShtW1l_Y15sY",
        "outputId": "64b4712c-7688-41a0-86b4-c33131637850"
      },
      "source": [
        "fig = tfds.show_examples(ds_train, ds_info, rows=4, cols=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x864 with 16 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bu4WgcVc2aGj",
        "outputId": "53085308-e21a-44ef-f35f-5effa86affae"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=['train','test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "def normalize_img(image, label):\n",
        "    return tf.cast(image, tf.float32)/255.0, label\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 64 \n",
        "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_test = ds_test.batch(128)\n",
        "ds_test = ds_test.prefetch(AUTOTUNE)\n",
        "\n",
        "model = keras.Sequential([\n",
        "     keras.Input((28,28,1)) ,\n",
        "     layers.Conv2D(32, 3, activation='relu'),\n",
        "     layers.Flatten(),\n",
        "     layers.Dense(10),                    \n",
        "])\n",
        "\n",
        "model.compile(\n",
        "     loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "     optimizer = keras.optimizers.Adam(lr = 0.001),\n",
        "     metrics = [\"accuracy\"],          \n",
        ")\n",
        "\n",
        "model.fit(ds_train, epochs =10, verbose=2)\n",
        "model.evaluate(ds_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "938/938 - 12s - loss: 0.2229 - accuracy: 0.9358\n",
            "Epoch 2/10\n",
            "938/938 - 2s - loss: 0.0786 - accuracy: 0.9777\n",
            "Epoch 3/10\n",
            "938/938 - 2s - loss: 0.0551 - accuracy: 0.9835\n",
            "Epoch 4/10\n",
            "938/938 - 2s - loss: 0.0421 - accuracy: 0.9876\n",
            "Epoch 5/10\n",
            "938/938 - 2s - loss: 0.0333 - accuracy: 0.9896\n",
            "Epoch 6/10\n",
            "938/938 - 2s - loss: 0.0266 - accuracy: 0.9924\n",
            "Epoch 7/10\n",
            "938/938 - 2s - loss: 0.0215 - accuracy: 0.9934\n",
            "Epoch 8/10\n",
            "938/938 - 2s - loss: 0.0163 - accuracy: 0.9954\n",
            "Epoch 9/10\n",
            "938/938 - 2s - loss: 0.0129 - accuracy: 0.9964\n",
            "Epoch 10/10\n",
            "938/938 - 2s - loss: 0.0113 - accuracy: 0.9964\n",
            "79/79 [==============================] - 1s 12ms/step - loss: 0.0691 - accuracy: 0.9824\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06911313533782959, 0.9824000000953674]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xsofGc68g5q"
      },
      "source": [
        "TRYING WITH TEXT DATA-IMDB DATASET"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "706YIDrP4-E4",
        "outputId": "1db05336-7af2-4c78-a066-d9280df6d21a"
      },
      "source": [
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"imdb_reviews\",\n",
        "    split=['train','test'],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "tokenizer = tfds.deprecated.text.Tokenizer()\n",
        "\n",
        "def build_vocab():\n",
        "    vocab = set()\n",
        "    for text, _ in ds_train:\n",
        "        vocab.update(tokenizer.tokenize(text.numpy().lower()))\n",
        "    return vocab\n",
        "\n",
        "vocab = build_vocab()\n",
        "\n",
        "encoder = tfds.deprecated.text.TokenTextEncoder(\n",
        "    vocab, oov_token=\"<UNK>\", lowercase=True, tokenizer=tokenizer\n",
        ")\n",
        "\n",
        "def my_enc(text_tensor, label):\n",
        "    encoded_text = encoder.encode(text_tensor.numpy())\n",
        "    return encoded_text, label\n",
        "\n",
        "\n",
        "def encode_map_fn(text, label):\n",
        "    # py_func doesn't set the shape of the returned tensors.\n",
        "    encoded_text, label = tf.py_function(\n",
        "        my_enc, inp=[text, label], Tout=(tf.int64, tf.int64)\n",
        "    )\n",
        "\n",
        "    # `tf.data.Datasets` work best if all components have a shape set\n",
        "    #  so set the shapes manually:\n",
        "    encoded_text.set_shape([None])\n",
        "    label.set_shape([])\n",
        "\n",
        "    return encoded_text, label\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "ds_train = ds_train.map(encode_map_fn, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(1000)\n",
        "ds_train = ds_train.padded_batch(32, padded_shapes=([None], ()))\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "ds_test = ds_test.map(encode_map_fn)\n",
        "ds_test = ds_test.padded_batch(32, padded_shapes=([None], ()))\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Masking(mask_value=0),\n",
        "        layers.Embedding(input_dim=len(vocab) + 2, output_dim=32),\n",
        "        layers.GlobalAveragePooling1D(),\n",
        "        layers.Dense(64, activation=\"relu\"),\n",
        "        layers.Dense(1),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile(\n",
        "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    optimizer=keras.optimizers.Adam(3e-4, clipnorm=1),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(ds_train, epochs=15, verbose=2)\n",
        "model.evaluate(ds_test)\n",
        "\n",
        "\n",
        "# def normalize_img(image, label):\n",
        "#     return tf.cast(image, tf.float32)/255.0, label\n",
        "\n",
        "# AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "# BATCH_SIZE = 64 \n",
        "# ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "# ds_train = ds_train.cache()\n",
        "# ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
        "# ds_train = ds_train.batch(BATCH_SIZE)\n",
        "# ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "# ds_test = ds_test.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "# ds_test = ds_test.batch(128)\n",
        "# ds_test = ds_test.prefetch(AUTOTUNE)\n",
        "\n",
        "# model = keras.Sequential([\n",
        "#      keras.Input((28,28,1)) ,\n",
        "#      layers.Conv2D(32, 3, activation='relu'),\n",
        "#      layers.Flatten(),\n",
        "#      layers.Dense(10),                    \n",
        "# ])\n",
        "\n",
        "# model.compile(\n",
        "#      loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "#      optimizer = keras.optimizers.Adam(lr = 0.001),\n",
        "#      metrics = [\"accuracy\"],          \n",
        "# )\n",
        "\n",
        "# model.fit(ds_train, epochs =10, verbose=2)\n",
        "# model.evaluate(ds_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "782/782 - 27s - loss: 0.6741 - accuracy: 0.5053\n",
            "Epoch 2/15\n",
            "782/782 - 14s - loss: 0.4846 - accuracy: 0.7306\n",
            "Epoch 3/15\n",
            "782/782 - 14s - loss: 0.3316 - accuracy: 0.8610\n",
            "Epoch 4/15\n",
            "782/782 - 14s - loss: 0.2664 - accuracy: 0.8948\n",
            "Epoch 5/15\n",
            "782/782 - 14s - loss: 0.2266 - accuracy: 0.9125\n",
            "Epoch 6/15\n",
            "782/782 - 14s - loss: 0.1971 - accuracy: 0.9268\n",
            "Epoch 7/15\n",
            "782/782 - 14s - loss: 0.1733 - accuracy: 0.9368\n",
            "Epoch 8/15\n",
            "782/782 - 14s - loss: 0.1527 - accuracy: 0.9464\n",
            "Epoch 9/15\n",
            "782/782 - 14s - loss: 0.1344 - accuracy: 0.9543\n",
            "Epoch 10/15\n",
            "782/782 - 14s - loss: 0.1193 - accuracy: 0.9607\n",
            "Epoch 11/15\n",
            "782/782 - 14s - loss: 0.1050 - accuracy: 0.9650\n",
            "Epoch 12/15\n",
            "782/782 - 14s - loss: 0.0926 - accuracy: 0.9704\n",
            "Epoch 13/15\n",
            "782/782 - 14s - loss: 0.0805 - accuracy: 0.9746\n",
            "Epoch 14/15\n",
            "782/782 - 14s - loss: 0.0720 - accuracy: 0.9774\n",
            "Epoch 15/15\n",
            "782/782 - 14s - loss: 0.0621 - accuracy: 0.9819\n",
            "782/782 [==============================] - 16s 20ms/step - loss: 0.3560 - accuracy: 0.8803\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.355975478887558, 0.8803200125694275]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dmy3W45FCa2E"
      },
      "source": [
        "CALLBACKS & CUSTOM CALLBACKS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S9D-zbcJBqZj",
        "outputId": "abc89ff5-99dd-47ca-c590-b088fac7823a"
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,  # will return tuple (img, label) otherwise dict\n",
        "    with_info=True,  # able to get info about dataset\n",
        ")\n",
        "\n",
        "\n",
        "def normalize_img(image, label):\n",
        "    \"\"\"Normalizes images\"\"\"\n",
        "    return tf.cast(image, tf.float32) / 255.0, label\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Setup for train dataset\n",
        "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input((28, 28, 1)),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        tf.keras.layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "save_callback = keras.callbacks.ModelCheckpoint(\n",
        "    \"checkpoint/\", save_weights_only=True, monitor=\"accuracy\", save_best_only=False,\n",
        ")\n",
        "\n",
        "class CustomCallback(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if logs.get(\"accuracy\") > 0.90:\n",
        "            print(\"Accuracy over 90% quitting training\")\n",
        "            self.model.stop_training = True\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(0.01),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "def scheduler(epoch, lr):\n",
        "    if epoch < 2:\n",
        "        return lr\n",
        "    else:\n",
        "        return lr * 0.99\n",
        "\n",
        "lr_scheduler = keras.callbacks.LearningRateScheduler(scheduler, verbose=1)\n",
        "\n",
        "model.fit(\n",
        "    ds_train,\n",
        "    epochs=10,\n",
        "    callbacks=[save_callback, lr_scheduler, CustomCallback()],\n",
        "    verbose=2,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.009999999776482582.\n",
            "469/469 - 6s - loss: 0.1474 - accuracy: 0.9547\n",
            "Accuracy over 90% quitting training\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe5b4638ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18pon8KeZ7Ua"
      },
      "source": [
        "CUSTOMIZING Model.fit\n",
        "\n",
        "(USEFUL IN GANs)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KiD62_IaAyE",
        "outputId": "6633a605-2c18-4c8b-fdf4-f5d5f8502173"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "x_train = x_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "x_test = x_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(28, 28, 1)),\n",
        "        layers.Conv2D(64, (3, 3), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
        "        layers.ReLU(),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10),\n",
        "    ],\n",
        "    name=\"model\",\n",
        ")\n",
        "\n",
        "\n",
        "class CustomFit(keras.Model):\n",
        "    def __init__(self, model):\n",
        "        super(CustomFit, self).__init__()\n",
        "        self.model = model\n",
        "\n",
        "    def compile(self, optimizer, loss):\n",
        "        super(CustomFit, self).compile()\n",
        "        self.optimizer = optimizer\n",
        "        self.loss = loss\n",
        "\n",
        "    def train_step(self, data):\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            # Caclulate predictions\n",
        "            y_pred = self.model(x, training=True)\n",
        "\n",
        "            # Loss\n",
        "            loss = self.loss(y, y_pred)\n",
        "\n",
        "        # Gradients\n",
        "        training_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, training_vars)\n",
        "\n",
        "        # Step with optimizer\n",
        "        self.optimizer.apply_gradients(zip(gradients, training_vars))\n",
        "        acc_metric.update_state(y, y_pred)\n",
        "\n",
        "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
        "\n",
        "    def test_step(self, data):\n",
        "        # Unpack the data\n",
        "        x, y = data\n",
        "\n",
        "        # Compute predictions\n",
        "        y_pred = self.model(x, training=False)\n",
        "\n",
        "        # Updates the metrics tracking the loss\n",
        "        loss = self.loss(y, y_pred)\n",
        "\n",
        "        # Update the metrics.\n",
        "        acc_metric.update_state(y, y_pred)\n",
        "        return {\"loss\": loss, \"accuracy\": acc_metric.result()}\n",
        "\n",
        "\n",
        "acc_metric = keras.metrics.SparseCategoricalAccuracy(name=\"accuracy\")\n",
        "\n",
        "training = CustomFit(model)\n",
        "training.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=3e-4),\n",
        "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        ")\n",
        "\n",
        "training.fit(x_train, y_train, batch_size=64, epochs=2)\n",
        "training.evaluate(x_test, y_test, batch_size=64)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Epoch 1/2\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.1736 - accuracy: 0.8924\n",
            "Epoch 2/2\n",
            "938/938 [==============================] - 5s 5ms/step - loss: 0.0583 - accuracy: 0.9594\n",
            "157/157 [==============================] - 0s 3ms/step - loss: 0.0455 - accuracy: 0.9668\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9677000045776367, 0.0007935084868222475]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vG183pF2_zd-"
      },
      "source": [
        "CUSTOM TRAINING LOOPS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIlzuXZP_6Tu",
        "outputId": "e9e4b42c-6fc1-4fd0-b212-dbc645c57b77"
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
        "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
        "\n",
        "(ds_train, ds_test), ds_info = tfds.load(\n",
        "    \"mnist\",\n",
        "    split=[\"train\", \"test\"],\n",
        "    shuffle_files=True,\n",
        "    as_supervised=True,\n",
        "    with_info=True,\n",
        ")\n",
        "\n",
        "\n",
        "def normalize_img(image, label):\n",
        "    \"\"\"Normalizes images\"\"\"\n",
        "    return tf.cast(image, tf.float32) / 255.0, label\n",
        "\n",
        "\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Setup for train dataset\n",
        "ds_train = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_train = ds_train.cache()\n",
        "ds_train = ds_train.shuffle(ds_info.splits[\"train\"].num_examples)\n",
        "ds_train = ds_train.batch(BATCH_SIZE)\n",
        "ds_train = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "# Setup for test Dataset\n",
        "ds_test = ds_train.map(normalize_img, num_parallel_calls=AUTOTUNE)\n",
        "ds_test = ds_train.batch(128)\n",
        "ds_test = ds_train.prefetch(AUTOTUNE)\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [\n",
        "        keras.Input((28, 28, 1)),\n",
        "        layers.Conv2D(32, 3, activation=\"relu\"),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(10, activation=\"softmax\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "num_epochs = 5\n",
        "optimizer = keras.optimizers.Adam()\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "# Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"\\nStart of Training Epoch {epoch}\")\n",
        "    for batch_idx, (x_batch, y_batch) in enumerate(ds_train):\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = model(x_batch, training=True)\n",
        "            loss = loss_fn(y_batch, y_pred)\n",
        "\n",
        "        gradients = tape.gradient(loss, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
        "        acc_metric.update_state(y_batch, y_pred)\n",
        "\n",
        "    train_acc = acc_metric.result()\n",
        "    print(f\"Accuracy over epoch {train_acc}\")\n",
        "    acc_metric.reset_states()\n",
        "\n",
        "# Test Loop\n",
        "for batch_idx, (x_batch, y_batch) in enumerate(ds_test):\n",
        "    y_pred = model(x_batch, training=False)\n",
        "    acc_metric.update_state(y_batch, y_pred)\n",
        "\n",
        "train_acc = acc_metric.result()\n",
        "print(f\"Accuracy over Test Set: {train_acc}\")\n",
        "acc_metric.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start of Training Epoch 0\n",
            "Accuracy over epoch 0.9239000082015991\n",
            "\n",
            "Start of Training Epoch 1\n",
            "Accuracy over epoch 0.9741833209991455\n",
            "\n",
            "Start of Training Epoch 2\n",
            "Accuracy over epoch 0.9823499917984009\n",
            "\n",
            "Start of Training Epoch 3\n",
            "Accuracy over epoch 0.9858333468437195\n",
            "\n",
            "Start of Training Epoch 4\n",
            "Accuracy over epoch 0.9889000058174133\n",
            "Accuracy over Test Set: 0.9906333088874817\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rbiauYLVQPP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}